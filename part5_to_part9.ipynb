{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ[\"LANGCHAIN_API\"] \n",
    "\n",
    "gemini_api = os.environ[\"GEMINI_API\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash-lite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part - 5 Multi Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "#load blog\n",
    " \n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths = (\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs= dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            class_ = (\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 50)\n",
    "\n",
    "splits= text_splitter.split_documents(blog_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index \n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/gemini-embedding-001\", \n",
    "    api_key=gemini_api,\n",
    "    credentials= None\n",
    ")\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents = splits,\n",
    "                                   embedding = embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"You are an AI language model assistant, Your takse is to generate five different versions of the given user questions and to retrieve relevant documents from the database. By generating multiple different perspectives on the user question, your goal is to make the user overcome some of the limitations of the distance based similarity search, provide these alternatives responses separated by newlines. Original question {question}\"\"\"\n",
    "\n",
    "prompt_pers = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_pers \n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.load import dumps, loads\n",
    "\n",
    "def get_uniq(documents : list[list]):\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "\n",
    "    return [loads(doc) for doc in unique_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dhruv\\AppData\\Local\\Temp\\ipykernel_5152\\4290818311.py:7: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#retrieve\n",
    "\n",
    "question = \"what is task decomposition for LLM agents ?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_uniq\n",
    "docs = retrieval_chain.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "#RAG \n",
    "\n",
    "template = \"\"\"answer the following question based on this context:\n",
    "        {context}\n",
    "        \n",
    "        Question : {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": retrieval_chain,\n",
    "     \"question\": itemgetter(\"question\")}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents refers to the process of breaking down large, complex tasks into smaller, more manageable subgoals. This allows the agent to handle intricate tasks more efficiently. This decomposition can be achieved through several methods:\\n\\n*   **Simple prompting:** Using instructions like \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\".\\n*   **Task-specific instructions:** Providing directives tailored to the task, such as \"Write a story outline.\" for novel writing.\\n*   **Human inputs:** Direct guidance from a human user.\\n*   **Chain of Thought (CoT):** Instructing the model to \"think step by step\" to decompose difficult tasks into simpler ones.\\n*   **Tree of Thoughts (ToT):** This approach extends CoT by exploring multiple reasoning possibilities at each step, generating several thoughts per step to create a tree-like structure of problem-solving.\\n*   **External classical planners:** Using tools like the Planning Domain Definition Language (PDDL) to describe the planning problem, where the LLM translates the problem into PDDL, an external planner generates a plan, and the LLM then translates the plan back into natural language. This method, known as LLM+P, outsources the planning step to an external tool.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rag_chain.invoke({\"question\" : question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 : RAG Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI language model assistant, Your task is to generate five different versions of the given user questions and to retrieve relevant documents from the database. By generating multiple different perspectives on the user question, your goal is to make the user overcome some of the limitations of the distance based similarity search, provide these alternatives responses separated by newlines. Original question {question}\"\"\"\n",
    "\n",
    "prompt_pers = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k = 60):\n",
    "    \"\"\"reciprocal rank fusion function that takes in multiple lists from ranked documents and an optional paramater k is used in the RRF formula\"\"\"\n",
    "\n",
    "    fused_scores = {}\n",
    "\n",
    "    for rank, doc in enumerate(docs):\n",
    "        doc_str = dumps(doc)\n",
    "\n",
    "        if doc_str not in fused_scores:\n",
    "            fused_scores[doc_str] = 0\n",
    "        \n",
    "        prev_score = fused_scores[doc_str]\n",
    "        fused_scores[doc_str] += 1 / (rank + k)\n",
    "    \n",
    "    reranked_res = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key = lambda x: x[1], reverse = True)\n",
    "    ]\n",
    "\n",
    "    return reranked_res\n",
    "\n",
    "ret_chain_fusion = generate_queries | retriever.map() | reciprocal_rank_fusion\n",
    "docs = ret_chain_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Task decomposition for LLM agents involves breaking down large, complex tasks into smaller, more manageable subgoals. This allows the agent to handle intricate tasks more efficiently. Methods for task decomposition include:',\n",
       " '',\n",
       " '*   **LLM with simple prompting:** Using prompts like \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\".',\n",
       " '*   **Task-specific instructions:** Providing instructions tailored to the specific task, such as \"Write a story outline.\" for novel writing.',\n",
       " '*   **Human inputs:** Relying on human guidance to define subgoals.',\n",
       " '*   **Chain of Thought (CoT):** Instructing the model to \"think step by step\" to decompose hard tasks into simpler ones, which also provides insight into the model\\'s thinking process.',\n",
       " '*   **Tree of Thoughts (ToT):** Extending CoT by exploring multiple reasoning possibilities at each step, generating several thoughts per step to create a tree structure, which can be searched using BFS or DFS.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\"context\": ret_chain_fusion, \n",
    "     \"question\": itemgetter(\"question\")} \n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part - 7 Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#Decomposition \n",
    "\n",
    "template = \"\"\"you are a helpful assistant that generates multiples sub questions related to an input question. \\n\n",
    "the goal is to break the input into a set of sub questions to help the user understand his requirements better and for the agent to be able to answer all of them \\n\n",
    "generate multiple queries related to the question \" {question} \\n\n",
    "please output (3 queries)\"\"\"\n",
    "\n",
    "prompt_dc = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries_dec = (prompt_dc | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "question = \"what are the components of a LLM system ?\"\n",
    "questions = generate_queries_dec.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are 3 sub-questions related to \"What are the components of an LLM system?\":',\n",
       " '',\n",
       " '1.  What are the core architectural building blocks that constitute a Large Language Model (LLM)?',\n",
       " '2.  Beyond the model itself, what other software and hardware elements are typically involved in deploying and running an LLM system?',\n",
       " '3.  What are the key data-related components necessary for training and operating an LLM?']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Answer recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dec = \"\"\"here is the question you need to answer:\n",
    "                \\n \\n {question} \\n \\n\n",
    "                here is any available bg question + answer pairs:\n",
    "                \\n \\n {q_a_pairs} \\n \\n\n",
    "                here is additional context relevant to this query:\n",
    "                \\n \\n {context} \\n \\n\n",
    "                use the above context and question answer pairs to ans this query in a better manner\"\"\"\n",
    "\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"format Q and A pair\"\"\"\n",
    "\n",
    "    formatted_str = \"\"\n",
    "    formatted_str += f\"Question: {question} \\n Answer: {answer} \\n \\n\"\n",
    "    return formatted_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "questions = [\n",
    "    q.strip()  \n",
    "    for q in questions\n",
    "    if q and q.strip()  \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_a_pairs = \"\"\n",
    "\n",
    "for q in questions:\n",
    "    rag_chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever,\n",
    "         \"question\": itemgetter(\"question\"),\n",
    "         \"q_a_pairs\": itemgetter(\"q_a_pairs\")}\n",
    "         | decomposition_prompt\n",
    "         | llm\n",
    "         | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = final_rag_chain.invoke({\"question\":q,\"q_a_pairs\":q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q,answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n---\\n\"+  q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Based on the provided context, the question about \"key data-related components necessary for training and operating an LLM\" cannot be answered. The text discusses LLM-powered autonomous agents, planning, task decomposition, and self-reflection, but it does not delve into the specifics of data requirements for training or operating LLMs.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langsmith import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hub = Client()\n",
    "prompt_rag = hub.pull_prompt(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_rag(question, prompt, sub_ques_gen_chain):\n",
    "    \"\"\"rag on each sub question\"\"\"\n",
    "\n",
    "    sub_ques = sub_ques_gen_chain.invoke({\"question\": question})\n",
    "    rag_res = []\n",
    "\n",
    "    for sub_qu in sub_ques:\n",
    "        if not sub_qu or sub_qu.strip():\n",
    "            continue\n",
    "        retrieved_docs = retriever.invoke(sub_qu)\n",
    "        answer = (prompt | llm | StrOutputParser()).invoke({\"context\": retrieved_docs, \"question\": sub_qu})\n",
    "\n",
    "        rag_res.append(answer)\n",
    "    \n",
    "    return rag_res, sub_ques\n",
    "\n",
    "answers, questions = retrieve_and_rag(question, prompt_rag, generate_queries_dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's a synthesis of the components of an LLM system based on the provided QA pairs:\\n\\nAn LLM system is composed of several key components that work together to process and generate human-like text. The core of the system is the **Large Language Model (LLM)** itself, which is a complex neural network trained on a massive dataset of text and code. This training allows the LLM to learn patterns, grammar, facts, reasoning abilities, and more.\\n\\nTo interact with the LLM and provide it with context for a specific task, an **input prompt** is used. This prompt guides the LLM's output by specifying the desired action, providing relevant information, or setting constraints.\\n\\nThe LLM then processes this input and generates a **response**. This response is the output of the system, designed to be coherent, relevant, and informative based on the prompt and the LLM's training.\\n\\nIn some advanced LLM systems, there might be additional components for **fine-tuning**. This process involves further training the pre-trained LLM on a smaller, task-specific dataset to adapt its capabilities for particular applications, improving its performance on specialized tasks.\\n\\nIn summary, the essential components of an LLM system are:\\n\\n*   **Large Language Model (LLM):** The foundational neural network trained on vast amounts of data.\\n*   **Input Prompt:** The user-provided text that guides the LLM's generation.\\n*   **Response:** The generated text output from the LLM.\\n*   **(Optional) Fine-tuning:** A process to further train the LLM for specific tasks.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_qa_pairs(questions, answers):\n",
    "    \"\"\"format question and answer pairs\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start = 1):\n",
    "        formatted_string += f\"Question {i}: {question} \\n answer {i} \\n \\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format_qa_pairs(questions, answers)\n",
    "\n",
    "template = \"\"\"Here is a set of QA pairs:\n",
    "{context}\n",
    "\n",
    "use these to synthesize a answers to the question: {question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\" :context , \"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Part - 8 step back "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\" : \"could the members of the police perform lawful arrests ?\",\n",
    "        \"output\" : \"what can be the members of the police do ?\",\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan sindel was born in what country ?\",\n",
    "        \"output\": \"what is jan sindel personal history ?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "#We now transform these to example messages\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt= example_prompt,\n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
    "        ),\n",
    "        # Few shot examples\n",
    "        few_shot_prompt,\n",
    "        # New question\n",
    "        (\"user\", \"{question}\"),  \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AI: What is task decomposition?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | llm | StrOutputParser()\n",
    "question = \"What is task decomposiion for a LLM agent?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for a LLM agent refers to the process of breaking down a large, complex task into smaller, more manageable subgoals. This is a crucial component of planning in LLM-powered autonomous agents, enabling them to efficiently handle intricate problems.\\n\\nHere\\'s a breakdown of how task decomposition is approached:\\n\\n*   **Purpose:** The primary goal is to transform a big, overwhelming task into a series of simpler, achievable steps. This not only makes the task easier to manage but also provides insights into the agent\\'s reasoning process.\\n\\n*   **Methods of Decomposition:**\\n    *   **Chain of Thought (CoT):** This is a standard prompting technique where the LLM is instructed to \"think step by step.\" By utilizing more computation during inference, the model can decompose complex tasks into a sequence of simpler ones. This method helps in interpreting the model\\'s thought process.\\n    *   **Tree of Thoughts (ToT):** An extension of CoT, ToT explores multiple reasoning possibilities at each step. It decomposes the problem into thought steps and then generates multiple thoughts for each step, forming a tree-like structure. This exploration can be guided by search algorithms like Breadth-First Search (BFS) or Depth-First Search (DFS), with states evaluated by a classifier or majority vote.\\n    *   **LLM with Simple Prompting:** This involves directly instructing the LLM to break down a task using prompts like \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\".\\n    *   **Task-Specific Instructions:** For certain types of tasks, specific instructions can be provided, such as \"Write a story outline\" for the task of writing a novel.\\n    *   **Human Inputs:** Decomposition can also be facilitated by human guidance.\\n    *   **External Classical Planners (LLM+P):** In some cases, an external classical planner can be used for long-horizon planning. This involves using the Planning Domain Definition Language (PDDL) as an intermediate interface. The LLM translates the problem into \"Problem PDDL,\" an external planner generates a PDDL plan based on an existing \"Domain PDDL,\" and the LLM then translates the plan back into natural language. This approach outsources the planning step to a specialized tool.\\n\\nIn essence, task decomposition is a foundational element that allows LLM agents to tackle complex problems by breaking them down into a series of logical and actionable steps, enhancing their problem-solving capabilities.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_prompt_template = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "# {normal_context}\n",
    "# {step_back_context}\n",
    "\n",
    "# Original Question: {question}\n",
    "# Answer:\"\"\"\n",
    "\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part - 9 HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here\\'s a passage answering \"What are task decompositions for LLM agents?\" in a scientific paper style:\\n\\n---\\n\\n**Passage:**\\n\\nTask decomposition for Large Language Model (LLM) agents refers to the process of breaking down a complex, overarching objective into a sequence of smaller, more manageable, and executable sub-tasks. LLMs, while possessing impressive generative capabilities and a broad understanding of language and concepts, often struggle with intricate, multi-step problems that require planning, reasoning, and interaction with external tools or environments. Task decomposition addresses this limitation by enabling the LLM to approach a large task in a structured and iterative manner. This involves identifying distinct stages or components of the desired outcome and formulating them as individual prompts or instructions that the LLM can process and execute. The output of one sub-task often serves as the input or context for the next, creating a dependency chain. This hierarchical or sequential breakdown allows the agent to:\\n\\n1.  **Reduce Cognitive Load:** Complex tasks can be overwhelming for a single LLM inference. Decomposition simplifies the problem space for each individual step.\\n2.  **Improve Accuracy and Reliability:** By focusing on a single, well-defined sub-task at a time, the LLM is more likely to generate accurate and relevant outputs for that specific step, reducing the propagation of errors.\\n3.  **Facilitate Tool Use and Integration:** Sub-tasks can be designed to trigger specific tool calls (e.g., web searches, code execution, API interactions), allowing the LLM agent to leverage external functionalities to gather information, perform calculations, or manipulate data.\\n4.  **Enable Planning and Reasoning:** The decomposition process itself can involve planning algorithms or reasoning modules that guide the LLM in determining the optimal sequence of sub-tasks. This can be achieved through explicit planning mechanisms or emergent behavior from prompting strategies.\\n5.  **Enhance Interpretability and Debugging:** When an LLM agent fails, examining the outputs of individual sub-tasks can help pinpoint the source of the error, making debugging and refinement of the agent\\'s behavior more efficient.\\n\\nEffectively, task decomposition transforms a monolithic problem into a solvable workflow, allowing LLM agents to tackle more sophisticated applications that require a degree of strategic thinking and execution beyond single-turn generation.\\n\\n---'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Please write a scientific paper passage to answer the question\n",
    "Question: {question}\n",
    "Passage:\"\"\"\n",
    "\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_docs_for_retrieval = (\n",
    "    prompt_hyde | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = \"what is task decompositions for llm agents\"\n",
    "generate_docs_for_retrieval.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Self-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain = generate_docs_for_retrieval | retriever\n",
    "\n",
    "retrieved_docs = retrieval_chain.invoke({\"question\" : question})\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM agents refers to the process of breaking down a complex task into smaller, more manageable subgoals. This enables the agent to handle intricate tasks more efficiently.\\n\\nThis decomposition can be achieved in several ways:\\n\\n*   **LLM with simple prompting:** This involves using straightforward prompts like \"Steps for XYZ.\\\\\\\\n1.\" or \"What are the subgoals for achieving XYZ?\".\\n*   **Task-specific instructions:** Providing instructions tailored to the specific task, such as \"Write a story outline.\" for novel writing.\\n*   **Human inputs:** Receiving guidance from humans to define the subtasks.\\n*   **Chain of Thought (CoT):** Instructing the LLM to \"think step by step\" to decompose hard tasks into simpler steps, which also provides insight into the model\\'s reasoning.\\n*   **Tree of Thoughts (ToT):** Extending CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into thought steps and generates multiple thoughts per step, forming a tree structure that can be searched using BFS or DFS.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# RAG\n",
    "template = \"\"\"Answer the following question based on this context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":retrieved_docs,\"question\":question})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
